{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# ===================================================\n",
    "# LAB ÚKOL: Promotnutí streamovaných tabulek na batch tabulky\n",
    "# Cíl: Z DLT stream tabulek vytvořit ne-streamované (batch) tabulky pro další zpracování, např. maskování nebo export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3618492-5ffb-4b7f-a337-6126cab73baf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# KROK 1: Získání prostředí a nastavení schématu\n",
    "# ÚKOL:\n",
    "# - Získej hodnotu proměnné prostředí (env) z widgetu \"pipeline.env\"\n",
    "# - Definuj proměnné: catalog, bronze_schema, silver_schema\n",
    "# - Přepni aktivní katalog a schéma pomocí spark.sql\n",
    "\n",
    "# env = dbutils.widgets.get(\"pipeline.env\")\n",
    "# catalog = \"principal_lab_db\"\n",
    "# bronze_schema = f\"{env}_bronze\"\n",
    "# silver_schema = f\"{env}_silver\"\n",
    "# spark.sql(f\"USE CATALOG {catalog}\")\n",
    "# spark.sql(f\"USE SCHEMA {silver_schema}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6017e276-20e6-47de-9726-127ab3ee8b19",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# KROK 2: Definice funkce pro převod streamované tabulky na batch\n",
    "# ÚKOL:\n",
    "# - Napiš funkci, která přijme název tabulky\n",
    "# - Načte danou tabulku pomocí spark.read.table(...)\n",
    "# - Zapíše ji jako batch (overwrite režim) pod nový název (např. <tabulka>_mask)\n",
    "\n",
    "# def promote_to_batch_table(table_name: str):\n",
    "#     ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KROK 3: Seznam tabulek ke konverzi\n",
    "# ÚKOL:\n",
    "# - Vytvoř seznam tabulek, které mají být konvertovány z DLT streamingu na batch tabulky\n",
    "# - Např.: dim_agents, dim_customers, ...\n",
    "\n",
    "# tables_to_promote = [\n",
    "#     \"dim_agents\",\n",
    "#     \"dim_customers\",\n",
    "#     ...\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KROK 4: Iterace přes všechny tabulky a spuštění konverze\n",
    "# ÚKOL:\n",
    "# - Použij cyklus for k zavolání funkce promote_to_batch_table pro každou tabulku ze seznamu\n",
    "\n",
    "# for table in tables_to_promote:\n",
    "#     promote_to_batch_table(table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_masking",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
